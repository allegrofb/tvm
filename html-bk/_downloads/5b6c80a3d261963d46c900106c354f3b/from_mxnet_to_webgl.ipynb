{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nDeploy Deep Learning Models to OpenGL and WebGL\n===============================================\n**Author**: `Zhixun Tan <https://github.com/phisiart>`_\n\nThis example shows how to build a neural network with NNVM python frontend and\ngenerate runtime library for WebGL running in a browser with TVM.\nTo run this notebook, you need to install tvm and nnvm.\nNotice that you need to build tvm with OpenGL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overview\n--------\nIn this tutorial, we will download a pre-trained resnet18 model from Gluon\nModel Zoo, and run image classification in 3 different ways:\n\n- Run locally:\n  We will compile the model into a TVM library with OpenGL device code and\n  directly run it locally.\n\n- Run in a browser through RPC:\n  We will compile the model into a JavaScript TVM library with WebGL device\n  code, and upload it to an RPC server that is hosting JavaScript TVM runtime\n  to run it.\n\n- Export a JavaScript library and run in a browser:\n  We will compile the model into a JavaScript TVM library with WebGL device\n  code, combine it with JavaScript TVM runtime, and pack everything together.\n  Then we will run it directly in a browser.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n\nimport numpy as np\nimport tvm\nimport nnvm.compiler\nimport nnvm.testing\n\n# This tutorial must be run with OpenGL backend enabled in TVM.\n# The NNVM CI does not enable OpenGL yet. But the user can run this script.\nopengl_enabled = tvm.module.enabled(\"opengl\")\n\n# To run the local demo, set this flag to True.\nrun_deploy_local = False\n\n# To run the RPC demo, set this flag to True.\nrun_deploy_rpc = False\n\n# To run the WebGL deploy demo, set this flag to True.\nrun_deploy_web = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download a Pre-trained Resnet18 Model\n-------------------------------------\nHere we define 2 functions:\n\n- A function that downloads a pre-trained resnet18 model from Gluon Model Zoo.\n  The model that we download is in MXNet format, we then transform it into an\n  NNVM computation graph.\n\n- A function that downloads a file that contains the name of all the image\n  classes in this model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_mxnet_resnet():\n    \"\"\"Load a pretrained resnet model from MXNet and transform that into NNVM\n       format.\n\n    Returns\n    -------\n    net : nnvm.Symbol\n        The loaded resnet computation graph.\n\n    params : dict[str -> NDArray]\n        The pretrained model parameters.\n\n    data_shape: tuple\n        The shape of the input tensor (an image).\n\n    out_shape: tuple\n        The shape of the output tensor (probability of all classes).\n    \"\"\"\n\n    print(\"Loading pretrained resnet model from MXNet...\")\n\n    # Download a pre-trained mxnet resnet18_v1 model.\n    from mxnet.gluon.model_zoo.vision import get_model\n    block = get_model('resnet18_v1', pretrained=True)\n\n    # Transform the mxnet model into NNVM.\n    # We want a probability so add a softmax operator.\n    sym, params = nnvm.frontend.from_mxnet(block)\n    sym = nnvm.sym.softmax(sym)\n\n    print(\"- Model loaded!\")\n    return sym, params, (1, 3, 224, 224), (1, 1000)\n\ndef download_synset():\n    \"\"\"Download a dictionary from class index to name.\n    This lets us know what our prediction actually is.\n\n    Returns\n    -------\n    synset : dict[int -> str]\n        The loaded synset.\n    \"\"\"\n\n    print(\"Downloading synset...\")\n\n    from mxnet import gluon\n\n    url = \"https://gist.githubusercontent.com/zhreshold/\" + \\\n          \"4d0b62f3d01426887599d4f7ede23ee5/raw/\" + \\\n          \"596b27d23537e5a1b5751d2b0481ef172f58b539/\" + \\\n          \"imagenet1000_clsid_to_human.txt\"\n    file_name = \"synset.txt\"\n\n    gluon.utils.download(url, file_name)\n    with open(file_name) as f:\n        synset = eval(f.read())\n\n    print(\"- Synset downloaded!\")\n    return synset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download Input Image\n--------------------\nHere we define 2 functions that prepare an image that we want to perform\nclassification on.\n\n- A function that downloads a cat image.\n\n- A function that performs preprocessing to an image so that it fits the\n  format required by the resnet18 model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def download_image():\n    \"\"\"Download a cat image and resize it to 224x224 which fits resnet.\n\n    Returns\n    -------\n    image : PIL.Image.Image\n        The loaded and resized image.\n    \"\"\"\n\n    print(\"Downloading cat image...\")\n\n    from matplotlib import pyplot as plt\n    from mxnet import gluon\n    from PIL import Image\n\n    url = \"https://github.com/dmlc/mxnet.js/blob/master/data/cat.png?raw=true\"\n    img_name = \"cat.jpg\"\n\n    gluon.utils.download(url, img_name)\n    image = Image.open(img_name).resize((224, 224))\n\n    print(\"- Cat image downloaded!\")\n\n    plt.imshow(image)\n    plt.show()\n\n    return image\n\ndef transform_image(image):\n    \"\"\"Perform necessary preprocessing to input image.\n\n    Parameters\n    ----------\n    image : numpy.ndarray\n        The raw image.\n\n    Returns\n    -------\n    image : numpy.ndarray\n        The preprocessed image.\n    \"\"\"\n\n    image = np.array(image) - np.array([123., 117., 104.])\n    image /= np.array([58.395, 57.12, 57.375])\n    image = image.transpose((2, 0, 1))\n    image = image[np.newaxis, :]\n    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compile the Model\n-----------------\nHere we define a function that invokes the NNVM compiler.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compile_net(net, target_host, target, data_shape, params):\n    \"\"\"Compiles an NNVM computation graph.\n\n    Parameters\n    ----------\n    net : nnvm.Graph\n        The NNVM computation graph.\n\n    target_host : str\n        The target to compile the host portion of the library.\n\n    target : str\n        The target to compile the device portion of the library.\n\n    data_shape : tuple\n        The shape of the input data (image).\n\n    params : dict[str -> NDArray]\n        Model parameters.\n\n    Returns\n    -------\n    graph : Graph\n        The final execution graph.\n\n    libmod : tvm.Module\n        The module that comes with the execution graph\n\n    params : dict[str -> NDArray]\n        The updated parameters of graph if params is passed.\n        This can be different from the params passed in.\n    \"\"\"\n\n    print(\"Compiling the neural network...\")\n\n    with nnvm.compiler.build_config(opt_level=0):\n        deploy_graph, lib, deploy_params = nnvm.compiler.build(\n            net,\n            target_host=target_host,\n            target=target,\n            shape={\"data\": data_shape},\n            params=params)\n\n    print(\"- Complilation completed!\")\n    return deploy_graph, lib, deploy_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Demo 1: Deploy Locally\n----------------------\nIn this demo, we will compile the model targetting the local machine.\n\nThen we will demonstrate how to save the compiled model as a shared library\nand load it back.\n\nFinally, we will run the model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def deploy_local():\n    \"\"\"Runs the demo that deploys a model locally.\n    \"\"\"\n\n    # Load resnet model.\n    net, params, data_shape, out_shape = load_mxnet_resnet()\n\n    # Compile the model.\n    # Note that we specify the the host target as \"llvm\".\n    deploy_graph, lib, deploy_params = compile_net(\n        net,\n        target_host=\"llvm\",\n        target=\"opengl\",\n        data_shape=data_shape,\n        params=params)\n\n    # Save the compiled module.\n    # Note we need to save all three files returned from the NNVM compiler.\n    print(\"Saving the compiled module...\")\n    from tvm.contrib import util\n    temp = util.tempdir()\n\n    path_lib = temp.relpath(\"deploy_lib.so\")\n    path_graph_json = temp.relpath(\"deploy_graph.json\")\n    path_params = temp.relpath(\"deploy_param.params\")\n\n    lib.export_library(path_lib)\n    with open(path_graph_json, \"w\") as fo:\n        fo.write(deploy_graph.json())\n    with open(path_params, \"wb\") as fo:\n        fo.write(nnvm.compiler.save_param_dict(deploy_params))\n\n    print(\"- Saved files:\", temp.listdir())\n\n    # Load the module back.\n    print(\"Loading the module back...\")\n    loaded_lib = tvm.module.load(path_lib)\n    with open(path_graph_json) as fi:\n        loaded_graph_json = fi.read()\n    with open(path_params, \"rb\") as fi:\n        loaded_params = bytearray(fi.read())\n    print(\"- Module loaded!\")\n\n    # Run the model! We will perform prediction on an image.\n    print(\"Running the graph...\")\n    from tvm.contrib import graph_runtime\n\n    module = graph_runtime.create(loaded_graph_json, loaded_lib, tvm.opengl(0))\n    module.load_params(loaded_params)\n\n    image = transform_image(download_image())\n    input_data = tvm.nd.array(image.astype(\"float32\"), ctx=tvm.opengl(0))\n\n    module.set_input(\"data\", input_data)\n    module.run()\n\n    # Retrieve the output.\n    out = module.get_output(0, tvm.nd.empty(out_shape, ctx=tvm.opengl(0)))\n    top1 = np.argmax(out.asnumpy())\n    synset = download_synset()\n    print('TVM prediction top-1:', top1, synset[top1])\n\nif run_deploy_local and opengl_enabled:\n    deploy_local()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Demo 2: Deploy the Model to WebGL Remotely with RPC\n-------------------------------------------------------\nFollowing the steps above, we can also compile the model for WebGL.\nTVM provides rpc module to help with remote deploying.\n\nWhen we deploy a model locally to OpenGL, the model consists of two parts:\nthe host LLVM part and the device GLSL part. Now that we want to deploy to\nWebGL, we need to leverage Emscripten to transform LLVM into JavaScript. In\norder to do that, we will need to specify the host target as\n'llvm -target=asmjs-unknown-emscripten -system-lib`. Then call Emscripten to\ncompile the LLVM binary output into a JavaScript file.\n\nFirst, we need to manually start an RPC server. Please follow the instructions\nin `tvm/web/README.md`. After following the steps, you should have a web page\nopened in a browser, and a Python script running a proxy.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def deploy_rpc():\n    \"\"\"Runs the demo that deploys a model remotely through RPC.\n    \"\"\"\n    from tvm import rpc\n    from tvm.contrib import util, emscripten\n\n    # As usual, load the resnet18 model.\n    net, params, data_shape, out_shape = load_mxnet_resnet()\n\n    # Compile the model.\n    # Note that this time we are changing the target.\n    # This is because we want to translate the host library into JavaScript\n    # through Emscripten.\n    graph, lib, params = compile_net(\n        net,\n        target_host=\"llvm -target=asmjs-unknown-emscripten -system-lib\",\n        target=\"opengl\",\n        data_shape=data_shape,\n        params=params)\n\n    # Now we want to deploy our model through RPC.\n    # First we ned to prepare the module files locally.\n    print(\"Saving the compiled module...\")\n\n    temp = util.tempdir()\n    path_obj = temp.relpath(\"deploy.bc\") # host LLVM part\n    path_dso = temp.relpath(\"deploy.js\") # host JavaScript part\n    path_gl = temp.relpath(\"deploy.gl\") # device GLSL part\n    path_json = temp.relpath(\"deploy.tvm_meta.json\")\n\n    lib.save(path_obj)\n    emscripten.create_js(path_dso, path_obj, side_module=True)\n    lib.imported_modules[0].save(path_gl)\n\n    print(\"- Saved files:\", temp.listdir())\n\n    # Connect to the RPC server.\n    print(\"Connecting to RPC server...\")\n    proxy_host = 'localhost'\n    proxy_port = 9090\n    remote = rpc.connect(proxy_host, proxy_port, key=\"js\")\n    print(\"- Connected to RPC server!\")\n\n    # Upload module to RPC server.\n    print(\"Uploading module to RPC server...\")\n    remote.upload(path_dso, \"deploy.dso\")\n    remote.upload(path_gl)\n    remote.upload(path_json)\n    print(\"- Upload completed!\")\n\n    # Load remote library.\n    print(\"Loading remote library...\")\n    fdev = remote.load_module(\"deploy.gl\")\n    fhost = remote.load_module(\"deploy.dso\")\n    fhost.import_module(fdev)\n    rlib = fhost\n    print(\"- Remote library loaded!\")\n\n    ctx = remote.opengl(0)\n\n    # Upload the parameters.\n    print(\"Uploading parameters...\")\n    rparams = {k: tvm.nd.array(v, ctx) for k, v in params.items()}\n    print(\"- Parameters uploaded!\")\n\n    # Create the remote runtime module.\n    print(\"Running remote module...\")\n    from tvm.contrib import graph_runtime\n    module = graph_runtime.create(graph, rlib, ctx)\n\n    # Set parameter.\n    module.set_input(**rparams)\n\n    # Set input data.\n    input_data = np.random.uniform(size=data_shape)\n    module.set_input('data', tvm.nd.array(input_data.astype('float32')))\n\n    # Run.\n    module.run()\n    print(\"- Remote module execution completed!\")\n\n    out = module.get_output(0, out=tvm.nd.empty(out_shape, ctx=ctx))\n    # Print first 10 elements of output.\n    print(out.asnumpy()[0][0:10])\n\nif run_deploy_rpc and opengl_enabled:\n    deploy_rpc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Demo 3: Deploy the Model to WebGL SystemLib\n-----------------------------------------------\nThis time we are not using RPC. Instead, we will compile the model and link it\nwith the entire tvm runtime into a single giant JavaScript file. Then we will\nrun the model using JavaScript.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def deploy_web():\n    \"\"\"Runs the demo that deploys to web.\n    \"\"\"\n\n    import base64\n    import json\n    import os\n    import shutil\n    import SimpleHTTPServer, SocketServer\n\n    from tvm.contrib import emscripten\n\n    curr_path = os.path.dirname(os.path.abspath(os.path.expanduser(os.getcwd())))\n    working_dir = os.getcwd()\n    output_dir = os.path.join(working_dir, \"resnet\")\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # As usual, load the resnet18 model.\n    net, params, data_shape, out_shape = load_mxnet_resnet()\n\n    # As usual, compile the model.\n    graph, lib, params = compile_net(\n        net,\n        target_host=\"llvm -target=asmjs-unknown-emscripten -system-lib\",\n        target=\"opengl\",\n        data_shape=data_shape,\n        params=params)\n\n    # Now we save the model and link it with the TVM web runtime.\n    path_lib = os.path.join(output_dir, \"resnet.js\")\n    path_graph = os.path.join(output_dir, \"resnet.json\")\n    path_params = os.path.join(output_dir, \"resnet.params\")\n    path_data_shape = os.path.join(output_dir, \"data_shape.json\")\n    path_out_shape = os.path.join(output_dir, \"out_shape.json\")\n\n    lib.export_library(path_lib, emscripten.create_js, options=[\n        \"-s\", \"USE_GLFW=3\",\n        \"-s\", \"USE_WEBGL2=1\",\n        \"-lglfw\",\n        \"-s\", \"TOTAL_MEMORY=1073741824\",\n    ])\n    with open(path_graph, \"w\") as fo:\n        fo.write(graph.json())\n    with open(path_params, \"w\") as fo:\n        fo.write(base64.b64encode(nnvm.compiler.save_param_dict(params)))\n\n    shutil.copyfile(os.path.join(curr_path, \"../tvm/web/tvm_runtime.js\"),\n                    os.path.join(output_dir, \"tvm_runtime.js\"))\n    shutil.copyfile(os.path.join(curr_path, \"web/resnet.html\"),\n                    os.path.join(output_dir, \"resnet.html\"))\n\n    # Now we want to save some extra files so that we can execute the model from\n    # JavaScript.\n    # - data shape\n    with open(path_data_shape, \"w\") as fo:\n        json.dump(list(data_shape), fo)\n    # - out shape\n    with open(path_out_shape, \"w\") as fo:\n        json.dump(list(out_shape), fo)\n    # - input image\n    image = download_image()\n    image.save(os.path.join(output_dir, \"data.png\"))\n    # - synset\n    synset = download_synset()\n    with open(os.path.join(output_dir, \"synset.json\"), \"w\") as fo:\n        json.dump(synset, fo)\n\n    print(\"Output files are in\", output_dir)\n\n    # Finally, we fire up a simple web server to serve all the exported files.\n    print(\"Now running a simple server to serve the files...\")\n    os.chdir(output_dir)\n    port = 8080\n    handler = SimpleHTTPServer.SimpleHTTPRequestHandler\n    httpd = SocketServer.TCPServer((\"\", port), handler)\n    print(\"Please open http://localhost:\" + str(port) + \"/resnet.html\")\n    httpd.serve_forever()\n\nif run_deploy_web and opengl_enabled:\n    deploy_web()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}