{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCompile CoreML Models\n=====================\n**Author**: `Joshua Z. Zhang <https://zhreshold.github.io/>`_\n\nThis article is an introductory tutorial to deploy CoreML models with NNVM.\n\nFor us to begin with, coremltools module is required to be installed.\n\nA quick solution is to install via pip\n\n.. code-block:: bash\n\n    pip install -U coremltools --user\n\nor please refer to official site\nhttps://github.com/apple/coremltools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import nnvm\nimport tvm\nimport coremltools as cm\nimport numpy as np\nfrom PIL import Image\n\ndef download(url, path, overwrite=False):\n    import os\n    if os.path.isfile(path) and not overwrite:\n        print('File {} existed, skip.'.format(path))\n        return\n    print('Downloading from url {} to {}'.format(url, path))\n    try:\n        import urllib.request\n        urllib.request.urlretrieve(url, path)\n    except:\n        import urllib\n        urllib.urlretrieve(url, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load pretrained CoreML model\n----------------------------\nWe will download and load a pretrained mobilenet classification network\nprovided by apple in this example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_url = 'https://docs-assets.developer.apple.com/coreml/models/MobileNet.mlmodel'\nmodel_file = 'mobilenet.mlmodel'\ndownload(model_url, model_file)\n# now you mobilenet.mlmodel on disk\nmlmodel = cm.models.MLModel(model_file)\n# we can load the graph as NNVM compatible model\nsym, params = nnvm.frontend.from_coreml(mlmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a test image\n------------------\nA single cat dominates the examples!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from PIL import Image\nimg_url = 'https://github.com/dmlc/mxnet.js/blob/master/data/cat.png?raw=true'\ndownload(img_url, 'cat.png')\nimg = Image.open('cat.png').resize((224, 224))\n#x = np.transpose(img, (2, 0, 1))[np.newaxis, :]\nimage = np.asarray(img)\nimage = image.transpose((2, 0, 1))\nx = image[np.newaxis, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compile the model on NNVM\n---------------------------\nWe should be familiar with the process right now.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import nnvm.compiler\ntarget = 'cuda'\nshape_dict = {'image': x.shape}\nwith nnvm.compiler.build_config(opt_level=2, add_pass=['AlterOpLayout']):\n    graph, lib, params = nnvm.compiler.build(sym, target, shape_dict, params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute on TVM\n-------------------\nThe process is no different from other example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tvm.contrib import graph_runtime\nctx = tvm.gpu(0)\ndtype = 'float32'\nm = graph_runtime.create(graph, lib, ctx)\n# set inputs\nm.set_input('image', tvm.nd.array(x.astype(dtype)))\nm.set_input(**params)\n# execute\nm.run()\n# get outputs\ntvm_output = m.get_output(0)\ntop1 = np.argmax(tvm_output.asnumpy()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look up synset name\n-------------------\nLook up prediction top 1 index in 1000 class synset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "synset_url = ''.join(['https://gist.githubusercontent.com/zhreshold/',\n                      '4d0b62f3d01426887599d4f7ede23ee5/raw/',\n                      '596b27d23537e5a1b5751d2b0481ef172f58b539/',\n                      'imagenet1000_clsid_to_human.txt'])\nsynset_name = 'synset.txt'\ndownload(synset_url, synset_name)\nwith open(synset_name) as f:\n    synset = eval(f.read())\nprint('Top-1 id', top1, 'class name', synset[top1])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}