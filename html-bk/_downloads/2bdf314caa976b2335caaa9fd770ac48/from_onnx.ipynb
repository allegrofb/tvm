{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCompile ONNX Models\n===================\n**Author**: `Joshua Z. Zhang <https://zhreshold.github.io/>`_\n\nThis article is an introductory tutorial to deploy ONNX models with NNVM.\n\nFor us to begin with, onnx module is required to be installed.\n\nA quick solution is to install protobuf compiler, and\n\n.. code-block:: bash\n\n    pip install onnx --user\n\nor please refer to offical site.\nhttps://github.com/onnx/onnx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import nnvm\nimport tvm\nimport onnx\nimport numpy as np\n\ndef download(url, path, overwrite=False):\n    import os\n    if os.path.isfile(path) and not overwrite:\n        print('File {} existed, skip.'.format(path))\n        return\n    print('Downloading from url {} to {}'.format(url, path))\n    try:\n        import urllib.request\n        urllib.request.urlretrieve(url, path)\n    except:\n        import urllib\n        urllib.urlretrieve(url, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load pretrained ONNX model\n---------------------------------------------\nThe example super resolution model used here is exactly the same model in onnx tutorial\nhttp://pytorch.org/tutorials/advanced/super_resolution_with_caffe2.html\nwe skip the pytorch model construction part, and download the saved onnx model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_url = ''.join(['https://gist.github.com/zhreshold/',\n                     'bcda4716699ac97ea44f791c24310193/raw/',\n                     '93672b029103648953c4e5ad3ac3aadf346a4cdc/',\n                     'super_resolution_0.2.onnx'])\ndownload(model_url, 'super_resolution.onnx', True)\n# now you have super_resolution.onnx on disk\nonnx_model = onnx.load('super_resolution.onnx')\n# we can load the graph as NNVM compatible model\nsym, params = nnvm.frontend.from_onnx(onnx_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a test image\n---------------------------------------------\nA single cat dominates the examples!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from PIL import Image\nimg_url = 'https://github.com/dmlc/mxnet.js/blob/master/data/cat.png?raw=true'\ndownload(img_url, 'cat.png')\nimg = Image.open('cat.png').resize((224, 224))\nimg_ycbcr = img.convert(\"YCbCr\")  # convert to YCbCr\nimg_y, img_cb, img_cr = img_ycbcr.split()\nx = np.array(img_y)[np.newaxis, np.newaxis, :, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compile the model on NNVM\n---------------------------------------------\nWe should be familiar with the process right now.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import nnvm.compiler\ntarget = 'cuda'\n# assume first input name is data\ninput_name = sym.list_input_names()[0]\nshape_dict = {input_name: x.shape}\nwith nnvm.compiler.build_config(opt_level=3):\n    graph, lib, params = nnvm.compiler.build(sym, target, shape_dict, params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute on TVM\n---------------------------------------------\nThe process is no different from other example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tvm.contrib import graph_runtime\nctx = tvm.gpu(0)\ndtype = 'float32'\nm = graph_runtime.create(graph, lib, ctx)\n# set inputs\nm.set_input(input_name, tvm.nd.array(x.astype(dtype)))\nm.set_input(**params)\n# execute\nm.run()\n# get outputs\noutput_shape = (1, 1, 672, 672)\ntvm_output = m.get_output(0, tvm.nd.empty(output_shape, dtype)).asnumpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display results\n---------------------------------------------\nWe put input and output image neck to neck\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nout_y = Image.fromarray(np.uint8((tvm_output[0, 0]).clip(0, 255)), mode='L')\nout_cb = img_cb.resize(out_y.size, Image.BICUBIC)\nout_cr = img_cr.resize(out_y.size, Image.BICUBIC)\nresult = Image.merge('YCbCr', [out_y, out_cb, out_cr]).convert('RGB')\ncanvas = np.full((672, 672*2, 3), 255)\ncanvas[0:224, 0:224, :] = np.asarray(img)\ncanvas[:, 672:, :] = np.asarray(result)\nplt.imshow(canvas.astype(np.uint8))\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}