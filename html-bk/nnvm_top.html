

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>NNVM Core Tensor Operators &mdash; tvm 0.5.dev documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/tvm_theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-dataframe.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Index" href="genindex.html" />
    <link rel="prev" title="Hybrid Frontend Developer Guide" href="dev/hybrid_script.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.5.dev
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="install/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/index.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="contribute/index.html">Contribute to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_links.html">Links to C++ and JS API References</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dev/index.html">Design and Developer Guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">NNVM Core Tensor Operators</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview-of-operators">Overview of Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="#detailed-definitions">Detailed Definitions</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">tvm</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>NNVM Core Tensor Operators</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/nnvm_top.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="nnvm-core-tensor-operators">
<h1>NNVM Core Tensor Operators<a class="headerlink" href="#nnvm-core-tensor-operators" title="Permalink to this headline">¶</a></h1>
<p>This page contains the list of core tensor operator primitives pre-defined in NNVM.
The core tensor operator primitives(<code class="docutils literal notranslate"><span class="pre">nnvm.top</span></code>) covers typical workloads in deep learning.
They can represent workloads in front-end frameworks, and provide basic building blocks for optimization.
Since deep learning is a fast evolving field and it is that possible to have operators that are not in here.
NNVM is designed for this problem and can easily new operators without changing the core library.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Each operator node in the graph IR contains the following two kinds of parameters.</p>
<ul class="simple">
<li><p>inputs: positional list of input tensors</p></li>
<li><p>attrs: attributes about operator(e.g. kernel_size in conv2d)</p></li>
</ul>
<p>This document lists both inputs and attributes in the parameter field.  You can distinguish them by the marked type. The inputs are of type Tensor, while the rest parameters are attributes.
To construct the graph with NNVM python API, a user can pass in the input Tensors as positional arguments, and attributes as keyword arguments.</p>
</div>
<div class="section" id="overview-of-operators">
<h2>Overview of Operators<a class="headerlink" href="#overview-of-operators" title="Permalink to this headline">¶</a></h2>
<p><strong>Level 1: Basic Operators</strong></p>
<p>This level enables fully connected multi-layer perceptron.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.dense" title="nnvm.symbol.dense"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.dense</span></code></a></p></td>
<td><p>Applies a linear transformation: <span class="math notranslate nohighlight">\(Y = XW^T + b\)</span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.relu" title="nnvm.symbol.relu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.relu</span></code></a></p></td>
<td><p>Computes rectified linear.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.prelu" title="nnvm.symbol.prelu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.prelu</span></code></a></p></td>
<td><p>Parametric version of a Rectified Linear Unit.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.tanh" title="nnvm.symbol.tanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.tanh</span></code></a></p></td>
<td><p>Computes hyperbolic tangent.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.sigmoid" title="nnvm.symbol.sigmoid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.sigmoid</span></code></a></p></td>
<td><p>Computes sigmoid.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.exp" title="nnvm.symbol.exp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.exp</span></code></a></p></td>
<td><p>Returns the exp input array, computed element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.log" title="nnvm.symbol.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.log</span></code></a></p></td>
<td><p>Returns the log input array, computed element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.sqrt" title="nnvm.symbol.sqrt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.sqrt</span></code></a></p></td>
<td><p>Returns the sqrt input array, computed element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.elemwise_add" title="nnvm.symbol.elemwise_add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.elemwise_add</span></code></a></p></td>
<td><p>Element-wise add</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.elemwise_sub" title="nnvm.symbol.elemwise_sub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.elemwise_sub</span></code></a></p></td>
<td><p>Element-wise substraction</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.elemwise_mul" title="nnvm.symbol.elemwise_mul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.elemwise_mul</span></code></a></p></td>
<td><p>Element-wise multiplication</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.elemwise_div" title="nnvm.symbol.elemwise_div"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.elemwise_div</span></code></a></p></td>
<td><p>Element-wise division</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.elemwise_sum" title="nnvm.symbol.elemwise_sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.elemwise_sum</span></code></a></p></td>
<td><p>Adds all input arguments element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.elemwise_mod" title="nnvm.symbol.elemwise_mod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.elemwise_mod</span></code></a></p></td>
<td><p>Element-wise modulo</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.elemwise_pow" title="nnvm.symbol.elemwise_pow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.elemwise_pow</span></code></a></p></td>
<td><p>Element-wise power</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.flatten" title="nnvm.symbol.flatten"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.flatten</span></code></a></p></td>
<td><p>Flattens the input into a 2-D array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.concatenate" title="nnvm.symbol.concatenate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.concatenate</span></code></a></p></td>
<td><p>Joins input arrays along a given axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.expand_dims" title="nnvm.symbol.expand_dims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.expand_dims</span></code></a></p></td>
<td><p>Inserts a new axis of size 1 into the array shape</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.squeeze" title="nnvm.symbol.squeeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.squeeze</span></code></a></p></td>
<td><p>Squeeze axises in the array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.split" title="nnvm.symbol.split"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.split</span></code></a></p></td>
<td><p>Splits an array along a particular axis into multiple sub-arrays.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.dropout" title="nnvm.symbol.dropout"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.dropout</span></code></a></p></td>
<td><p>Applies dropout operation to input array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.batch_norm" title="nnvm.symbol.batch_norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.batch_norm</span></code></a></p></td>
<td><p>Batch normalization layer (Ioffe and Szegedy, 2014).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.softmax" title="nnvm.symbol.softmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.softmax</span></code></a></p></td>
<td><p>Computes softmax.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.log_softmax" title="nnvm.symbol.log_softmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.log_softmax</span></code></a></p></td>
<td><p>Computes log softmax.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.pad" title="nnvm.symbol.pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.pad</span></code></a></p></td>
<td><p>Pad for n-D tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.block_grad" title="nnvm.symbol.block_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.block_grad</span></code></a></p></td>
<td><p>Blocks gradient computation for input.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.matmul" title="nnvm.symbol.matmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.matmul</span></code></a></p></td>
<td><p>Matrix multiplication of two arrays.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.resize" title="nnvm.symbol.resize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.resize</span></code></a></p></td>
<td><p>Perform resize to input array with nearest neighbour or bilinear interpolation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.upsampling" title="nnvm.symbol.upsampling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.upsampling</span></code></a></p></td>
<td><p>Perform upsampling to input array with nearest neighbour or bilinear interpolation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.take" title="nnvm.symbol.take"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.take</span></code></a></p></td>
<td><p>Take elements from an array along an axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.l2_normalize" title="nnvm.symbol.l2_normalize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.l2_normalize</span></code></a></p></td>
<td><p>L2NORMALIZE layer</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.flip" title="nnvm.symbol.flip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.flip</span></code></a></p></td>
<td><p>Reverse the elements of an array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.lrn" title="nnvm.symbol.lrn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.lrn</span></code></a></p></td>
<td><p>LRN layer</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.where" title="nnvm.symbol.where"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.where</span></code></a></p></td>
<td><p>Return the elements, either from x or y, depending on the condition.</p></td>
</tr>
</tbody>
</table>
<p><strong>Level 2: Convolutions</strong></p>
<p>This level enables typical convnet models.</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.conv2d" title="nnvm.symbol.conv2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.conv2d</span></code></a></p></td>
<td><p>2D convolution layer (e.g.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.conv2d_transpose" title="nnvm.symbol.conv2d_transpose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.conv2d_transpose</span></code></a></p></td>
<td><p>Transposed 2D convolution layer (sometimes called Deconvolution).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.max_pool2d" title="nnvm.symbol.max_pool2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.max_pool2d</span></code></a></p></td>
<td><p>Max pooling operation for one dimensional data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.avg_pool2d" title="nnvm.symbol.avg_pool2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.avg_pool2d</span></code></a></p></td>
<td><p>Average pooling operation for one dimensional data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.global_max_pool2d" title="nnvm.symbol.global_max_pool2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.global_max_pool2d</span></code></a></p></td>
<td><p>Global max pooling operation for 2D data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.global_avg_pool2d" title="nnvm.symbol.global_avg_pool2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.global_avg_pool2d</span></code></a></p></td>
<td><p>Global average pooling operation for 2D data.</p></td>
</tr>
</tbody>
</table>
<p><strong>Level 3: Additional Tensor Ops</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.reshape" title="nnvm.symbol.reshape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.reshape</span></code></a></p></td>
<td><p>Reshapes the input array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.copy" title="nnvm.symbol.copy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.copy</span></code></a></p></td>
<td><p>Copy tensor to another one.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.negative" title="nnvm.symbol.negative"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.negative</span></code></a></p></td>
<td><p>Elemenwise numeric negative</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.floor" title="nnvm.symbol.floor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.floor</span></code></a></p></td>
<td><p>Take floor input array, computed element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.ceil" title="nnvm.symbol.ceil"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.ceil</span></code></a></p></td>
<td><p>Take ceil input array, computed element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.round" title="nnvm.symbol.round"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.round</span></code></a></p></td>
<td><p>Round elements of the input to nearest integer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.trunc" title="nnvm.symbol.trunc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.trunc</span></code></a></p></td>
<td><p>Take truncated value of the input, element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.abs" title="nnvm.symbol.abs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.abs</span></code></a></p></td>
<td><p>Take absolute value of elements of the input.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.leaky_relu" title="nnvm.symbol.leaky_relu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.leaky_relu</span></code></a></p></td>
<td><p>Leaky version of a Rectified Linear Unit.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.__add_scalar__" title="nnvm.symbol.__add_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__add_scalar__</span></code></a></p></td>
<td><p>Tensor add scalar</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.__sub_scalar__" title="nnvm.symbol.__sub_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__sub_scalar__</span></code></a></p></td>
<td><p>Tensor substract scalar</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.__rsub_scalar__" title="nnvm.symbol.__rsub_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__rsub_scalar__</span></code></a></p></td>
<td><p>scalar substract Tensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.__mul_scalar__" title="nnvm.symbol.__mul_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__mul_scalar__</span></code></a></p></td>
<td><p>Tensor multiplies scalar</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.__div_scalar__" title="nnvm.symbol.__div_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__div_scalar__</span></code></a></p></td>
<td><p>Tensor divides scalar</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.__rdiv_scalar__" title="nnvm.symbol.__rdiv_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__rdiv_scalar__</span></code></a></p></td>
<td><p>scalar divides Tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.__pow_scalar__" title="nnvm.symbol.__pow_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__pow_scalar__</span></code></a></p></td>
<td><p>Tensor power scalar</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.__rpow_scalar__" title="nnvm.symbol.__rpow_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__rpow_scalar__</span></code></a></p></td>
<td><p>scalar power Tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.__lshift_scalar__" title="nnvm.symbol.__lshift_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__lshift_scalar__</span></code></a></p></td>
<td><p>Tensor left shift by scalar</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.__rshift_scalar__" title="nnvm.symbol.__rshift_scalar__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.__rshift_scalar__</span></code></a></p></td>
<td><p>Tensor right shift by scalar</p></td>
</tr>
</tbody>
</table>
<p><strong>Level 4: Broadcast and Reductions</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.transpose" title="nnvm.symbol.transpose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.transpose</span></code></a></p></td>
<td><p>Permutes the dimensions of an array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_to" title="nnvm.symbol.broadcast_to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_to</span></code></a></p></td>
<td><p>Broadcasts the input array to a new shape.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.sum" title="nnvm.symbol.sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.sum</span></code></a></p></td>
<td><p>Computes the sum of array elements over given axes.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.min" title="nnvm.symbol.min"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.min</span></code></a></p></td>
<td><p>Computes the min of array elements over given axes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.max" title="nnvm.symbol.max"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.max</span></code></a></p></td>
<td><p>Computes the max of array elements over given axes.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.mean" title="nnvm.symbol.mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.mean</span></code></a></p></td>
<td><p>Computes the mean of array elements over given axes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.prod" title="nnvm.symbol.prod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.prod</span></code></a></p></td>
<td><p>Computes the products of array elements over given axes.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_add" title="nnvm.symbol.broadcast_add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_add</span></code></a></p></td>
<td><p>Returns element-wise sum of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_sub" title="nnvm.symbol.broadcast_sub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_sub</span></code></a></p></td>
<td><p>Returns element-wise difference of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_mul" title="nnvm.symbol.broadcast_mul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_mul</span></code></a></p></td>
<td><p>Returns element-wise product of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_div" title="nnvm.symbol.broadcast_div"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_div</span></code></a></p></td>
<td><p>Returns element-wise division of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.clip" title="nnvm.symbol.clip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.clip</span></code></a></p></td>
<td><p>Clips (limits) the values in an array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.greater" title="nnvm.symbol.greater"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.greater</span></code></a></p></td>
<td><p>Greater function that returns a mask tensor with 1.0 if (left &gt; right), otherwise 0.0 element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.less" title="nnvm.symbol.less"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.less</span></code></a></p></td>
<td><p>Less function that returns a mask tensor with 1.0 if (left &lt; right), otherwise 0.0 element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.expand_like" title="nnvm.symbol.expand_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.expand_like</span></code></a></p></td>
<td><p>Expand an input array with the shape of second array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.reshape_like" title="nnvm.symbol.reshape_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.reshape_like</span></code></a></p></td>
<td><p>Reshapes the input array by the size of another array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.full" title="nnvm.symbol.full"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.full</span></code></a></p></td>
<td><p>Fill array with scalar value</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.full_like" title="nnvm.symbol.full_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.full_like</span></code></a></p></td>
<td><p>Return an scalar value array with the same shape and type as the input array</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.ones" title="nnvm.symbol.ones"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.ones</span></code></a></p></td>
<td><p>Fill target with ones</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.ones_like" title="nnvm.symbol.ones_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.ones_like</span></code></a></p></td>
<td><p>Return an array of ones with the same shape and type as the input array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.zeros" title="nnvm.symbol.zeros"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.zeros</span></code></a></p></td>
<td><p>Fill target with zeros</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.zeros_like" title="nnvm.symbol.zeros_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.zeros_like</span></code></a></p></td>
<td><p>Return an array of zeros with the same shape and type as the input array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.slice_like" title="nnvm.symbol.slice_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.slice_like</span></code></a></p></td>
<td><p>Slice the first input respect to the second input.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.strided_slice" title="nnvm.symbol.strided_slice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.strided_slice</span></code></a></p></td>
<td><p>Strided slice of an array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.argmax" title="nnvm.symbol.argmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.argmax</span></code></a></p></td>
<td><p>Creates an operation that finds the indices of the maximum values over a given axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.argmin" title="nnvm.symbol.argmin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.argmin</span></code></a></p></td>
<td><p>Creates an operation that finds the indices of the minimum values over a given axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.collapse_sum" title="nnvm.symbol.collapse_sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.collapse_sum</span></code></a></p></td>
<td><p>Reduces lhs to the shape of rhs via sum</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_equal" title="nnvm.symbol.broadcast_equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_equal</span></code></a></p></td>
<td><p>Returns element-wise x == y of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_greater_equal" title="nnvm.symbol.broadcast_greater_equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_greater_equal</span></code></a></p></td>
<td><p>Returns element-wise x &gt;= y of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_greater" title="nnvm.symbol.broadcast_greater"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_greater</span></code></a></p></td>
<td><p>Returns element-wise x &gt; y of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_left_shift" title="nnvm.symbol.broadcast_left_shift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_left_shift</span></code></a></p></td>
<td><p>Returns element-wise x &lt;&lt; y of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_less_equal" title="nnvm.symbol.broadcast_less_equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_less_equal</span></code></a></p></td>
<td><p>Returns element-wise x &lt;= y of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_less" title="nnvm.symbol.broadcast_less"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_less</span></code></a></p></td>
<td><p>Returns element-wise x &lt; y of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_max" title="nnvm.symbol.broadcast_max"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_max</span></code></a></p></td>
<td><p>Returns element-wise max of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_min" title="nnvm.symbol.broadcast_min"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_min</span></code></a></p></td>
<td><p>Returns element-wise minimum of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_mod" title="nnvm.symbol.broadcast_mod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_mod</span></code></a></p></td>
<td><p>Returns element-wise mod of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_not_equal" title="nnvm.symbol.broadcast_not_equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_not_equal</span></code></a></p></td>
<td><p>Returns element-wise x != y of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_pow" title="nnvm.symbol.broadcast_pow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_pow</span></code></a></p></td>
<td><p>Returns element-wise x^y of the input arrays with broadcasting.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.broadcast_right_shift" title="nnvm.symbol.broadcast_right_shift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.broadcast_right_shift</span></code></a></p></td>
<td><p>Returns element-wise x &gt;&gt; y of the input arrays with broadcasting.</p></td>
</tr>
</tbody>
</table>
<p><strong>Level 5: Vision Operators</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.multibox_prior" title="nnvm.symbol.multibox_prior"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.multibox_prior</span></code></a></p></td>
<td><p>“Generate prior(anchor) boxes from data, sizes and ratios.”</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.multibox_transform_loc" title="nnvm.symbol.multibox_transform_loc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.multibox_transform_loc</span></code></a></p></td>
<td><p>“Location transformation for multibox detection.”</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.nms" title="nnvm.symbol.nms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.nms</span></code></a></p></td>
<td><p>“Non-maximum suppression.”</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#nnvm.symbol.yolo_region" title="nnvm.symbol.yolo_region"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.yolo_region</span></code></a></p></td>
<td><p>Region layer</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#nnvm.symbol.yolo_reorg" title="nnvm.symbol.yolo_reorg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nnvm.symbol.yolo_reorg</span></code></a></p></td>
<td><p>Perform reorg operation on input array based on the stride value.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="detailed-definitions">
<h2>Detailed Definitions<a class="headerlink" href="#detailed-definitions" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="nnvm.symbol.dense">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">dense</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a linear transformation: <span class="math notranslate nohighlight">\(Y = XW^T + b\)</span>.</p>
<ul class="simple">
<li><p><strong>data</strong>: <cite>(x1, x2, …, xn, input_dim)</cite></p></li>
<li><p><strong>weight</strong>: <cite>(units, input_dim)</cite></p></li>
<li><p><strong>bias</strong>: <cite>(units,)</cite></p></li>
<li><p><strong>out</strong>: <cite>(x1, x2, …, xn, units)</cite></p></li>
</ul>
<p>The learnable parameters include both <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">use_bias</span></code> is set to be false, then the <code class="docutils literal notranslate"><span class="pre">bias</span></code> term is ignored.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L77</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>nD Tensor</em>) – Input data.</p></li>
<li><p><strong>weight</strong> (<em>2D Tensor</em>) – Weight matrix.</p></li>
<li><p><strong>bias</strong> (<em>1D Tensor</em>) – Bias parameter.</p></li>
<li><p><strong>units</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>required</em>) – Number of hidden units of the dense transformation.</p></li>
<li><p><strong>use_bias</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=1</em>) – Whether to use bias parameter</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.relu">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">relu</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.relu" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes rectified linear.</p>
<div class="math notranslate nohighlight">
\[max(input, 0)\]</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L128</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.prelu">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">prelu</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.prelu" title="Permalink to this definition">¶</a></dt>
<dd><p>Parametric version of a Rectified Linear Unit.
It accepts two arguments: an input <code class="docutils literal notranslate"><span class="pre">x</span></code> and a channelwise slope <code class="docutils literal notranslate"><span class="pre">alpha</span></code>
and computes the output as <span class="math notranslate nohighlight">\(PReLU(x) y = x &gt; 0 ? x : alpha * x\)</span>,
where <span class="math notranslate nohighlight">\(*\)</span> is an channelwise multiplication for each sample in the</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L550</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p></li>
<li><p><strong>alpha</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input channelwise alpha.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='1'</em>) – Specify which shape axis the channel is specified.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.tanh">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">tanh</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.tanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes hyperbolic tangent.</p>
<div class="math notranslate nohighlight">
\[Y = sinh(X) / cosh(X)\]</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L133</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.sigmoid">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">sigmoid</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.sigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes sigmoid.</p>
<div class="math notranslate nohighlight">
\[Y = 1 / (1 + exp(-X))\]</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L103</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.exp">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">exp</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the exp input array, computed element-wise.</p>
<div class="math notranslate nohighlight">
\[exp(x)\]</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L163</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.log">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">log</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the log input array, computed element-wise.</p>
<div class="math notranslate nohighlight">
\[log(x)\]</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L189</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.sqrt">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">sqrt</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.sqrt" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the sqrt input array, computed element-wise.</p>
<div class="math notranslate nohighlight">
\[\sqrt(x)\]</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L215</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.elemwise_add">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">elemwise_add</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.elemwise_add" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise add</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.elemwise_sub">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">elemwise_sub</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.elemwise_sub" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise substraction</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L264</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.elemwise_mul">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">elemwise_mul</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.elemwise_mul" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise multiplication</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L287</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.elemwise_div">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">elemwise_div</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.elemwise_div" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise division</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L312</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.elemwise_sum">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">elemwise_sum</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.elemwise_sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds all input arguments element-wise.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L776</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> (<a class="reference internal" href="api/python/nnvm/symbol.html#nnvm.symbol.Symbol" title="nnvm.symbol.Symbol"><em>Symbol</em></a><em>[</em><em>]</em>) – Positional input arguments</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.elemwise_mod">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">elemwise_mod</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.elemwise_mod" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise modulo</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L343</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.elemwise_pow">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">elemwise_pow</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.elemwise_pow" title="Permalink to this definition">¶</a></dt>
<dd><p>Element-wise power</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L355</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.flatten">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">flatten</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.flatten" title="Permalink to this definition">¶</a></dt>
<dd><p>Flattens the input into a 2-D array.</p>
<p>For an input array with shape <code class="docutils literal notranslate"><span class="pre">(d1,</span> <span class="pre">d2,</span> <span class="pre">...,</span> <span class="pre">dk)</span></code>, <cite>flatten</cite> operation reshapes
the input array into an output array of shape <code class="docutils literal notranslate"><span class="pre">(d1,</span> <span class="pre">d2*...*dk)</span></code>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">]</span>
<span class="p">],</span>
<span class="p">[</span>   <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">]</span>
<span class="p">]],</span>

<span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">],</span>
   <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L65</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.concatenate">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">concatenate</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.concatenate" title="Permalink to this definition">¶</a></dt>
<dd><p>Joins input arrays along a given axis.</p>
<p>The dimensions of the input arrays should be the same except the axis along
which they will be concatenated.
The dimension of the output array along the concatenated axis will be equal
to the sum of the corresponding dimensions of the input arrays.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">]]</span>
<span class="n">z</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">],[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">]]</span>

<span class="n">concatenate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">z</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
                            <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
                            <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
                            <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
                            <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">],</span>
                            <span class="p">[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
                            <span class="p">[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">],</span>
                            <span class="p">[</span> <span class="mf">8.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]]</span>

<span class="n">Note</span> <span class="n">that</span> <span class="n">you</span> <span class="n">cannot</span> <span class="n">concat</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">z</span> <span class="n">along</span> <span class="n">dimension</span> <span class="mi">1</span> <span class="n">since</span> <span class="n">dimension</span>
<span class="mi">0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">the</span> <span class="n">same</span> <span class="k">for</span> <span class="nb">all</span> <span class="n">the</span> <span class="nb">input</span> <span class="n">arrays</span><span class="o">.</span>

<span class="n">concatenate</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">z</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
                          <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">],</span>
                          <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L190</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>Tensor-or-Tensor</em><em>[</em><em>]</em>) – List of arrays to concatenate</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='1'</em>) – the axis to be concated.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.expand_dims">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">expand_dims</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.expand_dims" title="Permalink to this definition">¶</a></dt>
<dd><p>Inserts a new axis of size 1 into the array shape</p>
<p>For example, given <code class="docutils literal notranslate"><span class="pre">x</span></code> with shape <code class="docutils literal notranslate"><span class="pre">(2,3,4)</span></code>, then <code class="docutils literal notranslate"><span class="pre">expand_dims(x,</span> <span class="pre">axis=1,</span> <span class="pre">num_newaxis=5)</span></code>
will return a new array with shape <code class="docutils literal notranslate"><span class="pre">(2,1,1,1,1,1,3,4)</span></code>.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L243</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input tensor</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>required</em>) – the axis to be expanded.</p></li>
<li><p><strong>num_newaxis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='1'</em>) – Number of new axis to be inserted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.squeeze">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">squeeze</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.squeeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Squeeze axises in the array.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]]</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]</span>

<span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L726</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Source input</p></li>
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – The axis to squeeze in the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.split">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">split</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits an array along a particular axis into multiple sub-arrays.</p>
<p><strong>Note</strong> that <cite>indices_or_sections</cite> should evenly divide the length of the axis
along which to split the array.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L396</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Array to be splitted</p></li>
<li><p><strong>indices_or_sections</strong> (<em>tuple of &lt;int&gt;</em><em>, </em><em>required</em>) – Number of outputs to be splitted</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='1'</em>) – the axis to be splitted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.dropout">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">dropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies dropout operation to input array.</p>
<ul class="simple">
<li><p>During training, each element of the input is set to zero with probability p.
The whole array is rescaled by <span class="math notranslate nohighlight">\(1/(1-p)\)</span> to keep the expected
sum of the input unchanged.</p></li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L161</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input to which dropout will be applied</p></li>
<li><p><strong>rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=0.5</em>) – Fraction of the input that gets dropped out during training time.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.batch_norm">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">batch_norm</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.batch_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch normalization layer (Ioffe and Szegedy, 2014).
Normalizes the input at each batch, i.e. applies a transformation
that maintains the mean activation close to 0 and the activation
standard deviation close to 1.</p>
<div class="math notranslate nohighlight">
\[\begin{split}data\_mean[i] = mean(data[:,i,:,...]) \\
data\_var[i] = var(data[:,i,:,...])\end{split}\]</div>
<p>Then compute the normalized output, which has the same shape as input, as following:</p>
<div class="math notranslate nohighlight">
\[out[:,i,:,...] = \frac{data[:,i,:,...] - data\_mean[i]}{\sqrt{data\_var[i]+\epsilon}} * gamma[i] + beta[i]\]</div>
<p>Both <em>mean</em> and <em>var</em> returns a scalar by treating the input as a vector.</p>
<p>Assume the input has size <em>k</em> on axis 1, then both <code class="docutils literal notranslate"><span class="pre">gamma</span></code> and <code class="docutils literal notranslate"><span class="pre">beta</span></code> have shape <em>(k,)</em>.</p>
<p>Besides the inputs and the outputs, this operator accepts two auxiliary
states, <code class="docutils literal notranslate"><span class="pre">moving_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">moving_var</span></code>, which are <em>k</em>-length
vectors. They are global statistics for the whole dataset, which are updated
by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">moving_mean</span> <span class="o">=</span> <span class="n">moving_mean</span> <span class="o">*</span> <span class="n">momentum</span> <span class="o">+</span> <span class="n">data_mean</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span>
<span class="n">moving_var</span> <span class="o">=</span> <span class="n">moving_var</span> <span class="o">*</span> <span class="n">momentum</span> <span class="o">+</span> <span class="n">data_var</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span>
</pre></div>
</div>
<p>The parameter <code class="docutils literal notranslate"><span class="pre">axis</span></code> specifies which axis of the input shape denotes
the ‘channel’ (separately normalized groups).  The default is 1.  Specifying -1 sets the channel
axis to be the last item in the input shape.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This operator can be optimized away for inference.</p>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L301</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input to which dropout will be applied</p></li>
<li><p><strong>gamma</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The gamma scale factor</p></li>
<li><p><strong>beta</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The beta offset factor</p></li>
<li><p><strong>moving_mean</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – running mean of input</p></li>
<li><p><strong>moving_var</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – running variance of input</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='1'</em>) – Specify which shape axis the channel is specified.</p></li>
<li><p><strong>epsilon</strong> (<em>double</em><em>, </em><em>optional</em><em>, </em><em>default=1e-05</em>) – Small float added to variance to avoid dividing by zero.</p></li>
<li><p><strong>center</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=1</em>) – If True, add offset of <cite>beta</cite> to normalized tensor.If False, <cite>beta</cite> is ignored.</p></li>
<li><p><strong>scale</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=1</em>) – If True, multiply by <cite>gamma</cite>. If False, <cite>gamma</cite> is not used.When the next layer is piecewise linear (also e.g. <cite>nn.relu</cite>),this can be disabled since the scalingwill be done by the next layer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.softmax">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">softmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes softmax.</p>
<div class="math notranslate nohighlight">
\[\text{softmax}(x)_i = \frac{exp(x_i)}{\sum_j exp(x_j)}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This operator can be optimized away for inference.</p>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L339</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='-1'</em>) – The axis to sum over when computing softmax.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.log_softmax">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">log_softmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes log softmax.</p>
<div class="math notranslate nohighlight">
\[\text{log_softmax}(x)_i = \log \frac{exp(x_i)}{\sum_j exp(x_j)}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This operator can be optimized away for inference.</p>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L398</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='-1'</em>) – The axis to sum over when computing softmax.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.pad">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">pad</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.pad" title="Permalink to this definition">¶</a></dt>
<dd><p>Pad for n-D tensor.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L596</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>n-D Tensor</em>) – Input data.</p></li>
<li><p><strong>pad_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – The value to be padded.</p></li>
<li><p><strong>pad_width</strong> (<em>tuple of &lt;tuple of &lt;int&gt;&gt;</em><em>, </em><em>required</em>) – Number of values padded to the edges of each axis, in the format of ((before_1, after_1), … (before_N, after_N))</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.block_grad">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">block_grad</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.block_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Blocks gradient computation for input.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L800</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.matmul">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">matmul</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.matmul" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix multiplication of two arrays.</p>
<p><code class="docutils literal notranslate"><span class="pre">dot</span></code>’s behavior depends on the input array dimensions:</p>
<ul>
<li><p>1-D arrays: inner product of vectors</p></li>
<li><p>2-D arrays: matrix multiplication</p></li>
<li><p>N-D arrays: a sum product over the last axis of the first input and the first
axis of the second input</p>
<p>For example, given 3-D <code class="docutils literal notranslate"><span class="pre">x</span></code> with shape <cite>(n,m,k)</cite> and <code class="docutils literal notranslate"><span class="pre">y</span></code> with shape <cite>(k,r,s)</cite>, the
result array will have shape <cite>(n,m,r,s)</cite>. It is computed by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,:]</span><span class="o">*</span><span class="n">y</span><span class="p">[:,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">])</span>
</pre></div>
</div>
</li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/matrix_op.cc:L88</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>transpose_a</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If true then transpose the first input before dot.</p></li>
<li><p><strong>transpose_b</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If true then transpose the second input before dot.</p></li>
<li><p><strong>lhs</strong> (<em>NDArray-or-Symbol</em>) – The first input</p></li>
<li><p><strong>rhs</strong> (<em>NDArray-or-Symbol</em>) – The second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.resize">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">resize</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.resize" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform resize to input array with nearest neighbour or bilinear interpolation.</p>
<ul>
<li><dl class="simple">
<dt><strong>data</strong>: data is 4D array of shape</dt><dd><p>(batch_size, channels, in_height, in_width) for NCHW
(batch_size, in_height, in_width, channels) for NHWC</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>out</strong>: Output is 4D array of shape</dt><dd><p>for layout NCHW
(batch_size, channels, size[0], size[1])</p>
<p>for layout NHWC
(batch_size, size[0], size[1], channels)</p>
</dd>
</dl>
</li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/image/resize.cc:L79</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p></li>
<li><p><strong>size</strong> (<em>, </em><em>required</em>) – Output size</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='NCHW'</em>) – Dimension ordering of data. Can be ‘NCHW’, ‘NHWC’, etc.’N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and widthdimensions respectively. Resize is applied on the ‘H’ and’W’ dimensions.</p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='BILINEAR'</em>) – Specify the mode to use for scaling.NEAREST_NEIGHBOR -  Nearest NeighborBILINEAR - Bilinear Interpolation</p></li>
<li><p><strong>align_corners</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Should be true to preserve the values at the corner pixels</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.upsampling">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">upsampling</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.upsampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform upsampling to input array with nearest neighbour or bilinear interpolation.</p>
<ul>
<li><dl class="simple">
<dt><strong>data</strong>: data is 4D array of shape</dt><dd><p>(batch_size, channels, in_height, in_width) for NCHW
(batch_size, in_height, in_width, channels) for NHWC</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>out</strong>: Output is 4D array of shape</dt><dd><p>for layout NCHW
(batch_size, channels, in_height*scale, in_width*scale)</p>
<p>for layout NHWC
(batch_size, in_height*scale, in_width*scale, channels)</p>
</dd>
</dl>
</li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/upsampling.cc:L77</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p></li>
<li><p><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>required</em>) – upsampling scaling factor</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='NCHW'</em>) – Dimension ordering of data. Can be ‘NCHW’, ‘NHWC’, etc.’N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and widthdimensions respectively. Upsampling is applied on the ‘H’ and’W’ dimensions.</p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='NEAREST_NEIGHBOR'</em>) – Specify the mode to use for scaling.NEAREST_NEIGHBOR -  Nearest NeighborBILINEAR - Bilinear Interpolation</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.take">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">take</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.take" title="Permalink to this definition">¶</a></dt>
<dd><p>Take elements from an array along an axis.</p>
<p>When axis is not None, this function does the same thing as ‘fancy’ indexing
(indexing arrays using arrays); however, it can be easier to use if you need
elements along a given axis.</p>
<p><strong>Note</strong> that when axis is none the flattened input array is used.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="p">[[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
     <span class="p">[</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">take</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="n">a</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]]</span>
<span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">take</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                            <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L1128</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Array to be indexed</p></li>
<li><p><strong>indices</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The indices of the values to extract</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default='None'</em>) – the axis over which to select values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.l2_normalize">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">l2_normalize</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.l2_normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>L2NORMALIZE layer</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L752</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.flip">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">flip</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.flip" title="Permalink to this definition">¶</a></dt>
<dd><p>Reverse the elements of an array.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
     <span class="p">[</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>

<span class="n">flip</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
                <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">]]</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
      <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]],</span>

     <span class="p">[[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
      <span class="p">[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]]]</span>

<span class="n">flip</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
                 <span class="p">[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]],</span>

                <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
                 <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]]]</span>

<span class="n">flip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
                               <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">]],</span>

                              <span class="p">[[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">],</span>
                               <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L1016</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Source input</p></li>
<li><p><strong>axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='0'</em>) – the axis to be reveresed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.lrn">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">lrn</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.lrn" title="Permalink to this definition">¶</a></dt>
<dd><p>LRN layer</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L729</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.where">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">where</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.where" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the elements, either from x or y, depending on the condition.</p>
<p>Given three ndarrays, condition, x, and y, return an ndarray with the elements
from x or y, depending on the elements from condition are true or false.
x and y must have the same shape. If condition has the same shape as x,
each element in the output array is from x if the corresponding element
in the condition is true, and from y if false.</p>
<p>If condition does not have the same shape as x, it must be a 1D array whose
size is the same as x’s first dimension size. Each row of the output array
is from x’s row if the corresponding element from condition is true, and
from y’s row if false.</p>
<p>Note that all non-zero values are interpreted as True in condition.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
<span class="n">cond</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>


<span class="n">cond</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">where</span><span class="p">(</span><span class="n">cond</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L1325</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>condition</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Condition array</p></li>
<li><p><strong>x</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – First array to be selected</p></li>
<li><p><strong>y</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Second array to be selected</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.conv2d">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">conv2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>2D convolution layer (e.g. spatial convolution over images).</p>
<p>This layer creates a convolution kernel that is convolved
with the layer input to produce a tensor of
outputs. If <cite>use_bias</cite> is True,
a bias vector is created and added to the outputs.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>data</strong>: This depends on the <cite>layout</cite> parameter. Input is 4D array of shape</dt><dd><p>(batch_size, in_channels, height, width) if <cite>layout</cite> is <cite>NCHW</cite>.</p>
</dd>
</dl>
</li>
<li><p><strong>weight</strong>: (channels, in_channels, kernel_size[0], kernel_size[1])</p></li>
<li><p><strong>bias</strong>: (channels,)</p></li>
<li><dl class="simple">
<dt><strong>out</strong>:  This depends on the <cite>layout</cite> parameter. Output is 4D array of shape</dt><dd><p>(batch_size, channels, out_height, out_width) if <cite>layout</cite> is <cite>NCHW</cite>.</p>
</dd>
</dl>
</li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/convolution.cc:L307</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p></li>
<li><p><strong>weight</strong> (<em>4D Tensor</em>) – Weight matrix.</p></li>
<li><p><strong>bias</strong> (<em>1D Tensor</em>) – Bias parameter.</p></li>
<li><p><strong>channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>required</em>) – The dimensionality of the output spacei.e. the number of output channels in the convolution.</p></li>
<li><p><strong>kernel_size</strong> (<em>, </em><em>required</em>) – Specifies the dimensions of the convolution window.</p></li>
<li><p><strong>strides</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>1</em><em>,</em><em>1</em><em>]</em>) – Specifies the strides of the convolution.</p></li>
<li><p><strong>padding</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>0</em><em>,</em><em>0</em><em>]</em>) – If padding is non-zero, then the input is implicitly zero-paddedon both sides for padding number of points</p></li>
<li><p><strong>dilation</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>1</em><em>,</em><em>1</em><em>]</em>) – Specifies the dilation rate to use for dilated convolution.</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='1'</em>) – Controls the connections between inputs and outputs.At groups=1, all inputs are convolved to all outputs.At groups=2, the operation becomes equivalent to having two convolutionlayers side by side, each seeing half the input channels, and producinghalf the output channels, and both subsequently concatenated.</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='NCHW'</em>) – Dimension ordering of input data. Can be ‘NCHW’, ‘NHWC’, etc.’N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and widthdimensions respectively. Convolution is applied on the ‘H’ and’W’ dimensions.</p></li>
<li><p><strong>out_layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='__undef__'</em>) – Dimension ordering of output. Can be ‘NCHW’, ‘NHWC’, etc.’N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and widthdimensions respectively. Default to be same as input layout.</p></li>
<li><p><strong>kernel_layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='OIHW'</em>) – Dimension ordering of weight. Can be ‘OIHW’, ‘OIHW16o16i’, etc.’O’, ‘I’, ‘H’, ‘W’ stands for num_filter, input_channel, height, and widthdimensions respectively.</p></li>
<li><p><strong>out_dtype</strong> (<em>{'float16'</em><em>, </em><em>'float32'</em><em>, </em><em>'float64'</em><em>, </em><em>'int16'</em><em>, </em><em>'int32'</em><em>, </em><em>'int64'</em><em>, </em><em>'int8'</em><em>, </em><em>'same'</em><em>, </em><em>'uint16'</em><em>, </em><em>'uint32'</em><em>, </em><em>'uint64'</em><em>, </em><em>'uint8'}</em><em>,</em><em>optional</em><em>, </em><em>default='same'</em>) – Output data type, set to explicit type under mixed precision setting</p></li>
<li><p><strong>use_bias</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=1</em>) – Whether the layer uses a bias vector.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.conv2d_transpose">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">conv2d_transpose</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.conv2d_transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>Transposed 2D convolution layer (sometimes called Deconvolution).</p>
<p>The need for transposed convolutions generally arises
from the desire to use a transformation going in the opposite direction
of a normal convolution, i.e., from something that has the shape of the
output of some convolution to something that has the shape of its input
while maintaining a connectivity pattern that is compatible with
said convolution.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>data</strong>: This depends on the <cite>layout</cite> parameter. Input is 4D array of shape</dt><dd><p>(batch_size, in_channels, height, width) if <cite>layout</cite> is <cite>NCHW</cite>.</p>
</dd>
</dl>
</li>
<li><p><strong>weight</strong>: (in_channels, channels, kernel_size[0], kernel_size[1])</p></li>
<li><p><strong>bias</strong>: (channels,)</p></li>
<li><p><strong>out</strong>:  This depends on the <cite>layout</cite> parameter. Output is 4D array of shape</p></li>
</ul>
<p>v            (batch_size, channels, out_height, out_width) if <cite>layout</cite> is <cite>NCHW</cite>.</p>
<blockquote>
<div><dl class="simple">
<dt>out_height and out_width are calculated as::</dt><dd><p>out_height = (height-1)*strides[0]-2*padding[0]+kernel_size[0]+output_padding[0]
out_width = (width-1)*strides[1]-2*padding[1]+kernel_size[1]+output_padding[1]</p>
</dd>
</dl>
</div></blockquote>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/convolution.cc:L550</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p></li>
<li><p><strong>weight</strong> (<em>4D Tensor</em>) – Weight matrix.</p></li>
<li><p><strong>bias</strong> (<em>1D Tensor</em>) – Bias parameter.</p></li>
<li><p><strong>channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>required</em>) – The dimensionality of the output spacei.e. the number of output channels in the convolution.</p></li>
<li><p><strong>kernel_size</strong> (<em>, </em><em>required</em>) – Specifies the dimensions of the convolution window.</p></li>
<li><p><strong>strides</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>1</em><em>,</em><em>1</em><em>]</em>) – Specifies the strides of the convolution.</p></li>
<li><p><strong>output_padding</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>0</em><em>,</em><em>0</em><em>]</em>) – Zero-padding added to one side of the output.</p></li>
<li><p><strong>padding</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>0</em><em>,</em><em>0</em><em>]</em>) – If padding is non-zero, then the input is implicitly zero-paddedon both sides for padding number of points</p></li>
<li><p><strong>dilation</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>1</em><em>,</em><em>1</em><em>]</em>) – Specifies the dilation rate to use for dilated convolution.</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='1'</em>) – Controls the connections between inputs and outputs.At groups=1, all inputs are convolved to all outputs.At groups=2, the operation becomes equivalent to having two convolutionlayers side by side, each seeing half the input channels, and producinghalf the output channels, and both subsequently concatenated.</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='NCHW'</em>) – Dimension ordering of data. Can be ‘NCHW’, ‘NHWC’, etc.’N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and widthdimensions respectively. Convolution is applied on the ‘H’ and’W’ dimensions.</p></li>
<li><p><strong>kernel_layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='OIHW'</em>) – Dimension ordering of data and weight. Can be ‘OIHW’, ‘OIHW16o16i’, etc.’O’, ‘I’, ‘H’, ‘W’ stands for num_filter, input_channel, height, and widthdimensions respectively.</p></li>
<li><p><strong>out_dtype</strong> (<em>{'float16'</em><em>, </em><em>'float32'</em><em>, </em><em>'float64'</em><em>, </em><em>'int16'</em><em>, </em><em>'int32'</em><em>, </em><em>'int64'</em><em>, </em><em>'int8'</em><em>, </em><em>'same'</em><em>, </em><em>'uint16'</em><em>, </em><em>'uint32'</em><em>, </em><em>'uint64'</em><em>, </em><em>'uint8'}</em><em>,</em><em>optional</em><em>, </em><em>default='same'</em>) – Output data type, set to explicit type under mixed precision setting</p></li>
<li><p><strong>use_bias</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=1</em>) – Whether the layer uses a bias vector.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.max_pool2d">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">max_pool2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.max_pool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Max pooling operation for one dimensional data.</p>
<ul>
<li><dl class="simple">
<dt><strong>data</strong>: This depends on the <cite>layout</cite> parameter. Input is 4D array of shape</dt><dd><p>(batch_size, channels, height, width) if <cite>layout</cite> is <cite>NCHW</cite>.</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>out</strong>: This depends on the <cite>layout</cite> parameter. Output is 4D array of shape</dt><dd><p>(batch_size, channels, out_height, out_width)  if <cite>layout</cite> is <cite>NCHW</cite>.
out_height and out_width are calculated as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">out_height</span> <span class="o">=</span> <span class="n">floor</span><span class="p">((</span><span class="n">height</span><span class="o">+</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">padding</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="n">pool_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span>
<span class="n">out_width</span> <span class="o">=</span> <span class="n">floor</span><span class="p">((</span><span class="n">width</span><span class="o">+</span><span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">padding</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">-</span><span class="n">pool_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">strides</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span>
</pre></div>
</div>
<dl class="simple">
<dt>where padding will be an expanded array based on number of values passed as::</dt><dd><p>one int : all sides same padding used.
two int : bottom, right use same as top and left.
four int: padding width in the order of (top, left, bottom, right).</p>
</dd>
</dl>
<p>When <cite>ceil_mode</cite> is <cite>True</cite>, ceil will be used instead of floor in this
equation.</p>
</dd>
</dl>
</li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/pooling.cc:L139</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p></li>
<li><p><strong>pool_size</strong> (<em>, </em><em>required</em>) – Size of the pooling windows..</p></li>
<li><p><strong>strides</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>1</em><em>,</em><em>1</em><em>]</em>) – Specifies the strides of the convolution.</p></li>
<li><p><strong>padding</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>0</em><em>,</em><em>0</em><em>]</em>) – If padding is non-zero, then the input is implicitly zero-paddedPadding support both symmetric and asymmetric asone int : same padding used on all sidestwo int : bottom, right will use same padding as top, leftfour int : padding width in the order of (top, left, bottom, right)</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='NCHW'</em>) – Dimension ordering of data and weight. Can be ‘NCHW’, ‘NHWC’, etc.’N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and widthdimensions respectively. Convolution is applied on the ‘H’ and’W’ dimensions.</p></li>
<li><p><strong>ceil_mode</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – When true, will use ceil instead of floor to compute the output shape.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.avg_pool2d">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">avg_pool2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.avg_pool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Average pooling operation for one dimensional data.</p>
<ul>
<li><dl class="simple">
<dt><strong>data</strong>: This depends on the <cite>layout</cite> parameter. Input is 4D array of shape</dt><dd><p>(batch_size, channels, height, width) if <cite>layout</cite> is <cite>NCHW</cite>.</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>out</strong>: This depends on the <cite>layout</cite> parameter. Output is 4D array of shape</dt><dd><p>(batch_size, channels, out_height, out_width)  if <cite>layout</cite> is <cite>NCHW</cite>.
out_height and out_width are calculated as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">out_height</span> <span class="o">=</span> <span class="n">floor</span><span class="p">((</span><span class="n">height</span><span class="o">+</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">padding</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="n">pool_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="n">strides</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span>
<span class="n">out_width</span> <span class="o">=</span> <span class="n">floor</span><span class="p">((</span><span class="n">width</span><span class="o">+</span><span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">padding</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">-</span><span class="n">pool_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">strides</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">+</span><span class="mi">1</span>
</pre></div>
</div>
<dl class="simple">
<dt>where padding will be an expanded array based on number of values passed as::</dt><dd><p>one int : all sides same padding used.
two int : bottom, right use same as top and left.
four int: padding width in the order of (top, left, bottom, right).</p>
</dd>
</dl>
<p>When <cite>ceil_mode</cite> is <cite>True</cite>, ceil will be used instead of floor in this
equation.</p>
</dd>
</dl>
</li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/pooling.cc:L227</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p></li>
<li><p><strong>pool_size</strong> (<em>, </em><em>required</em>) – Size of the pooling windows..</p></li>
<li><p><strong>strides</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>1</em><em>,</em><em>1</em><em>]</em>) – Specifies the strides of the convolution.</p></li>
<li><p><strong>padding</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>0</em><em>,</em><em>0</em><em>]</em>) – If padding is non-zero, then the input is implicitly zero-paddedPadding support both symmetric and asymmetric asone int : same padding used on all sidestwo int : bottom, right will use same padding as top, leftfour int : padding width in the order of (top, left, bottom, right)</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='NCHW'</em>) – Dimension ordering of data and weight. Can be ‘NCHW’, ‘NHWC’, etc.’N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and widthdimensions respectively. Convolution is applied on the ‘H’ and’W’ dimensions.</p></li>
<li><p><strong>ceil_mode</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – When true, will use ceil instead of floor to compute the output shape.</p></li>
<li><p><strong>count_include_pad</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – When true, will include padding to compute the average</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.global_max_pool2d">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">global_max_pool2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.global_max_pool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Global max pooling operation for 2D data.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>data</strong>: This depends on the <cite>layout</cite> parameter. Input is 4D array of shape</dt><dd><p>(batch_size, channels, height, width) if <cite>layout</cite> is <cite>NCHW</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>out</strong>: This depends on the <cite>layout</cite> parameter. Output is 4D array of shape</dt><dd><p>(batch_size, channels, 1, 1)  if <cite>layout</cite> is <cite>NCHW</cite>.</p>
</dd>
</dl>
</li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/pooling.cc:L343</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='NCHW'</em>) – Dimension ordering of data and weight. Can be ‘NCHW’, ‘NHWC’, etc.’N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and widthdimensions respectively. Convolution is applied on the ‘H’ and’W’ dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.global_avg_pool2d">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">global_avg_pool2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.global_avg_pool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Global average pooling operation for 2D data.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>data</strong>: This depends on the <cite>layout</cite> parameter. Input is 4D array of shape</dt><dd><p>(batch_size, channels, height, width) if <cite>layout</cite> is <cite>NCHW</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>out</strong>: This depends on the <cite>layout</cite> parameter. Output is 4D array of shape</dt><dd><p>(batch_size, channels, 1, 1)  if <cite>layout</cite> is <cite>NCHW</cite>.</p>
</dd>
</dl>
</li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/pooling.cc:L384</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>4D Tensor</em>) – Input data.</p></li>
<li><p><strong>layout</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default='NCHW'</em>) – Dimension ordering of data and weight. Can be ‘NCHW’, ‘NHWC’, etc.’N’, ‘C’, ‘H’, ‘W’ stands for batch, channel, height, and widthdimensions respectively. Convolution is applied on the ‘H’ and’W’ dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.reshape">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">reshape</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.reshape" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshapes the input array.</p>
<p>Given an array and a shape, this function returns a copy of the array in the new shape.
The shape is a tuple of integers such as (2,3,4). The size of the new shape should be same as the size of the input array.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]]</span>
</pre></div>
</div>
<p>To give user more convenience in without doing manual shape inference,
some dimensions of the shape can take special values from the set {0, -1, -2, -3, -4}.
The significance of each is explained below:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">0</span></code>  copy this dimension from the input to the output shape.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-1</span></code> infers the dimension of the output shape by using the remainder of the input dimensions
keeping the size of the new array same as that of the input array.
At most one dimension of shape can be -1.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">24</span><span class="p">,)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-2</span></code> copy all/remainder of the input dimensions to the output shape.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-3</span></code> use the product of two consecutive dimensions of the input shape as the output dimension.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
<span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">12</span><span class="p">)</span>
<span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-4</span></code> split one dimension of the input into two dimensions passed subsequent to -4 in shape (can contain -1).</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="o">-</span> <span class="nb">input</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="n">output</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L599</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p></li>
<li><p><strong>shape</strong> (<em>tuple of &lt;&gt;</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.copy">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">copy</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy tensor to another one.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L390</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.negative">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">negative</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.negative" title="Permalink to this definition">¶</a></dt>
<dd><p>Elemenwise numeric negative</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L368</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.floor">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">floor</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.floor" title="Permalink to this definition">¶</a></dt>
<dd><p>Take floor input array, computed element-wise.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L39</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.ceil">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">ceil</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.ceil" title="Permalink to this definition">¶</a></dt>
<dd><p>Take ceil input array, computed element-wise.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L51</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.round">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">round</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.round" title="Permalink to this definition">¶</a></dt>
<dd><p>Round elements of the input to nearest integer.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L75</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.trunc">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">trunc</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.trunc" title="Permalink to this definition">¶</a></dt>
<dd><p>Take truncated value of the input, element-wise.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L63</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.abs">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">abs</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.abs" title="Permalink to this definition">¶</a></dt>
<dd><p>Take absolute value of elements of the input.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L87</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.leaky_relu">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">leaky_relu</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.leaky_relu" title="Permalink to this definition">¶</a></dt>
<dd><p>Leaky version of a Rectified Linear Unit.</p>
<p><cite>y = x &gt; 0 ? x : alpha * x</cite></p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/nn/nn.cc:L459</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p></li>
<li><p><strong>alpha</strong> (<em>double</em><em>, </em><em>optional</em><em>, </em><em>default=0.25</em>) – slope coefficient for the negative half axis.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__add_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__add_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__add_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor add scalar</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L551</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__sub_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__sub_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__sub_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor substract scalar</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L570</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__rsub_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__rsub_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__rsub_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>scalar substract Tensor</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L588</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__mul_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__mul_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__mul_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor multiplies scalar</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L641</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__div_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__div_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__div_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor divides scalar</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L664</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__rdiv_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__rdiv_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__rdiv_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>scalar divides Tensor</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L687</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__pow_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__pow_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__pow_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor power scalar</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L717</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__rpow_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__rpow_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__rpow_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>scalar power Tensor</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L747</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__lshift_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__lshift_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__lshift_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor left shift by scalar</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L609</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.__rshift_scalar__">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">__rshift_scalar__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.__rshift_scalar__" title="Permalink to this definition">¶</a></dt>
<dd><p>Tensor right shift by scalar</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L625</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>scalar</strong> (<em>double</em><em>, </em><em>required</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.transpose">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">transpose</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>Permutes the dimensions of an array.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
     <span class="p">[</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>

<span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
                <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]]</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
      <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]],</span>

     <span class="p">[[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
      <span class="p">[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]]]</span>

<span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">],</span>
                 <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">]],</span>

                <span class="p">[[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
                 <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]]]</span>

<span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">=</span> <span class="p">[[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
                               <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]],</span>

                              <span class="p">[[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
                               <span class="p">[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L843</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Source input</p></li>
<li><p><strong>axes</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – Target axis order. By default the axes will be inverted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_to">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_to</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcasts the input array to a new shape.</p>
<p>Broadcasting is a mechanism that allows NDArrays to perform arithmetic operations
with arrays of different shapes efficiently without creating multiple copies of arrays.
Also see, <a class="reference external" href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">Broadcasting</a> for more explanation.</p>
<p>Broadcasting is allowed on axes with size 1, such as from <cite>(2,1,3,1)</cite> to
<cite>(2,8,3,9)</cite>. Elements will be duplicated on the broadcasted axes.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">broadcast_to</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
                                        <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">]])</span>
</pre></div>
</div>
<p>The dimension which you do not want to change can also be kept as <cite>0</cite> which means copy the original value.
So with <cite>shape=(2,0)</cite>, we will obtain the same result as in the above example.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L72</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p></li>
<li><p><strong>shape</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – The shape of the desired array. We can set the dim to zero if it’s same as the original. E.g <cite>A = broadcast_to(B, shape=(10, 0, 0))</cite></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.sum">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">sum</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the sum of array elements over given axes.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">]]]</span>

<span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">[[</span>  <span class="mf">4.</span>   <span class="mf">8.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">10.</span>   <span class="mf">9.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">21.</span>   <span class="mf">6.</span><span class="p">]]</span>

<span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="p">[</span> <span class="mf">12.</span>  <span class="mf">19.</span>  <span class="mf">27.</span><span class="p">]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/reduce.cc:L156</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – <p>The axis or axes along which to perform the reduction.</p>
<blockquote>
<div><p>The default, <cite>axis=()</cite>, will compute over all elements into a
scalar array with shape <cite>(1,)</cite>.</p>
<p>If <cite>axis</cite> is int, a reduction is performed on a particular axis.</p>
<p>If <cite>axis</cite> is a tuple of ints, a reduction is performed on all the axes
specified in the tuple.</p>
<p>If <cite>exclude</cite> is true, reduction will be performed on the axes that are
NOT in axis instead.</p>
</div></blockquote>
</p></li>
<li><p><strong>keepdims</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If this is set to <cite>True</cite>, the reduced axes are left in the result as dimension with size one.</p></li>
<li><p><strong>exclude</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to perform reduction on axis that are NOT in axis instead.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.min">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">min</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.min" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the min of array elements over given axes.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/reduce.cc:L224</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – <p>The axis or axes along which to perform the reduction.</p>
<blockquote>
<div><p>The default, <cite>axis=()</cite>, will compute over all elements into a
scalar array with shape <cite>(1,)</cite>.</p>
<p>If <cite>axis</cite> is int, a reduction is performed on a particular axis.</p>
<p>If <cite>axis</cite> is a tuple of ints, a reduction is performed on all the axes
specified in the tuple.</p>
<p>If <cite>exclude</cite> is true, reduction will be performed on the axes that are
NOT in axis instead.</p>
</div></blockquote>
</p></li>
<li><p><strong>keepdims</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If this is set to <cite>True</cite>, the reduced axes are left in the result as dimension with size one.</p></li>
<li><p><strong>exclude</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to perform reduction on axis that are NOT in axis instead.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.max">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">max</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.max" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the max of array elements over given axes.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/reduce.cc:L191</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – <p>The axis or axes along which to perform the reduction.</p>
<blockquote>
<div><p>The default, <cite>axis=()</cite>, will compute over all elements into a
scalar array with shape <cite>(1,)</cite>.</p>
<p>If <cite>axis</cite> is int, a reduction is performed on a particular axis.</p>
<p>If <cite>axis</cite> is a tuple of ints, a reduction is performed on all the axes
specified in the tuple.</p>
<p>If <cite>exclude</cite> is true, reduction will be performed on the axes that are
NOT in axis instead.</p>
</div></blockquote>
</p></li>
<li><p><strong>keepdims</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If this is set to <cite>True</cite>, the reduced axes are left in the result as dimension with size one.</p></li>
<li><p><strong>exclude</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to perform reduction on axis that are NOT in axis instead.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.mean">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">mean</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the mean of array elements over given axes.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">]]]</span>

<span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="p">[</span><span class="mf">3.22</span><span class="p">]</span>

<span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="p">[</span> <span class="mf">2.</span>  <span class="mf">3.16666667</span>  <span class="mf">4.5</span><span class="p">]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/reduce.cc:L340</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – <p>The axis or axes along which to perform the reduction.</p>
<blockquote>
<div><p>The default, <cite>axis=()</cite>, will compute over all elements into a
scalar array with shape <cite>(1,)</cite>.</p>
<p>If <cite>axis</cite> is int, a reduction is performed on a particular axis.</p>
<p>If <cite>axis</cite> is a tuple of ints, a reduction is performed on all the axes
specified in the tuple.</p>
<p>If <cite>exclude</cite> is true, reduction will be performed on the axes that are
NOT in axis instead.</p>
</div></blockquote>
</p></li>
<li><p><strong>keepdims</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If this is set to <cite>True</cite>, the reduced axes are left in the result as dimension with size one.</p></li>
<li><p><strong>exclude</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to perform reduction on axis that are NOT in axis instead.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.prod">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">prod</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.prod" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the products of array elements over given axes.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">]]]</span>

<span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">[</span><span class="mi">35562240</span><span class="p">]</span>

<span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="p">[</span> <span class="mi">36</span>  <span class="mi">480</span>  <span class="mi">2058</span><span class="p">]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/reduce.cc:L375</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – <p>The axis or axes along which to perform the reduction.</p>
<blockquote>
<div><p>The default, <cite>axis=()</cite>, will compute over all elements into a
scalar array with shape <cite>(1,)</cite>.</p>
<p>If <cite>axis</cite> is int, a reduction is performed on a particular axis.</p>
<p>If <cite>axis</cite> is a tuple of ints, a reduction is performed on all the axes
specified in the tuple.</p>
<p>If <cite>exclude</cite> is true, reduction will be performed on the axes that are
NOT in axis instead.</p>
</div></blockquote>
</p></li>
<li><p><strong>keepdims</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If this is set to <cite>True</cite>, the reduced axes are left in the result as dimension with size one.</p></li>
<li><p><strong>exclude</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to perform reduction on axis that are NOT in axis instead.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_add">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_add</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_add" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise sum of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">0.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">1.</span><span class="p">]]</span>

<span class="n">broadcast_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
                       <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L242</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_sub">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_sub</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_sub" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise difference of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">0.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">1.</span><span class="p">]]</span>

<span class="n">broadcast_sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
                       <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L268</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_mul">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_mul</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_mul" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise product of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">0.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">1.</span><span class="p">]]</span>

<span class="n">broadcast_mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L296</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_div">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_div</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_div" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise division of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">3.</span><span class="p">]]</span>

<span class="n">broadcast_div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
                       <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L329</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.clip">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">clip</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.clip" title="Permalink to this definition">¶</a></dt>
<dd><p>Clips (limits) the values in an array.
Given an interval, values outside the interval are clipped to the interval edges.
Clipping <code class="docutils literal notranslate"><span class="pre">x</span></code> between <cite>a_min</cite> and <cite>a_x</cite> would be:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a_min</span><span class="p">,</span> <span class="n">a_max</span><span class="p">)</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a_max</span><span class="p">),</span> <span class="n">a_min</span><span class="p">))</span>
</pre></div>
</div>
<dl class="simple">
<dt>Example::</dt><dd><p>x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
clip(x,1,8) = [ 1.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  8.]</p>
</dd>
</dl>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L883</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>NDArray-or-Symbol</em>) – Input array.</p></li>
<li><p><strong>a_min</strong> (<em>double</em><em>, </em><em>required</em>) – Minimum value such that value smaller then this will be clipped.</p></li>
<li><p><strong>a_max</strong> (<em>double</em><em>, </em><em>required</em>) – Maximum value such that value larger then this will be clipped.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.greater">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">greater</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.greater" title="Permalink to this definition">¶</a></dt>
<dd><p>Greater function that returns a mask tensor
with 1.0 if (left &gt; right), otherwise 0.0 element-wise.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L815</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – First input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.less">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">less</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.less" title="Permalink to this definition">¶</a></dt>
<dd><p>Less function that returns a mask tensor
with 1.0 if (left &lt; right), otherwise 0.0 element-wise.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L833</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – First input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.expand_like">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">expand_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.expand_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Expand an input array with the shape of second array.
This operation can be thought of as a composition of expand_dims and broadcast_to.
If the dimensions are already expanded then it just broadcasts.
Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">12.</span>  <span class="mf">19.</span>  <span class="mf">27.</span><span class="p">]</span>
<span class="nb">input</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,)</span>
<span class="n">new_shape_array</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">]],</span>
                   <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">]],</span>
                   <span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">3</span><span class="p">]]]</span>
<span class="n">new_shape_array</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">expand_like</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">new_shape_array</span><span class="p">)</span> <span class="o">=</span>
                  <span class="p">[[[</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">],[</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">],[</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">]],</span>
                   <span class="p">[[</span><span class="mi">19</span><span class="p">,</span><span class="mi">19</span><span class="p">],[</span><span class="mi">19</span><span class="p">,</span><span class="mi">19</span><span class="p">],[</span><span class="mi">19</span><span class="p">,</span><span class="mi">19</span><span class="p">]],</span>
                   <span class="p">[[</span><span class="mi">27</span><span class="p">,</span><span class="mi">27</span><span class="p">],[</span><span class="mi">27</span><span class="p">,</span><span class="mi">27</span><span class="p">],[</span><span class="mi">27</span><span class="p">,</span><span class="mi">27</span><span class="p">]]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L284</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Source input</p></li>
<li><p><strong>shape_like</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input with new shape</p></li>
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – <p>The axis or axes along which to perform the indicator rule.</p>
<blockquote>
<div><p>The default, <cite>axis=()</cite>, will compute over all elements into a
scalar array with shape <cite>(1,)</cite>.</p>
<p>If <cite>axis</cite> is int, rule is applied on a particular axis.</p>
<p>If <cite>axis</cite> is a tuple of ints, rule is applied on all the axes
specified in the tuple.</p>
<p>If <cite>exclude</cite> is true, rule will be applied on the axes that are
NOT in axis instead.</p>
</div></blockquote>
</p></li>
<li><p><strong>exclude</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to apply rule on axis that are NOT in axis instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.reshape_like">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">reshape_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.reshape_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshapes the input array by the size of another array.
For an input array with shape <code class="docutils literal notranslate"><span class="pre">(d1,</span> <span class="pre">d2,</span> <span class="pre">...,</span> <span class="pre">dk)</span></code>, <cite>reshape_like</cite> operation reshapes
the input array into an output array with the same shape as the second input array.
.. note:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sizes</span> <span class="k">for</span> <span class="n">both</span> <span class="n">array</span> <span class="n">should</span> <span class="n">be</span> <span class="n">compatible</span><span class="o">.</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L631</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p></li>
<li><p><strong>shape_like</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.full">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">full</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.full" title="Permalink to this definition">¶</a></dt>
<dd><p>Fill array with scalar value</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L415</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – </p></li>
<li><p><strong>dtype</strong> (<em>{'float16'</em><em>, </em><em>'float32'</em><em>, </em><em>'float64'</em><em>, </em><em>'int16'</em><em>, </em><em>'int32'</em><em>, </em><em>'int64'</em><em>, </em><em>'int8'</em><em>, </em><em>'uint16'</em><em>, </em><em>'uint32'</em><em>, </em><em>'uint64'</em><em>, </em><em>'uint8'}</em><em>,</em><em>optional</em><em>, </em><em>default='float32'</em>) – Target data type.</p></li>
<li><p><strong>fill_value</strong> (<em>double</em><em>, </em><em>required</em>) – Scalar value to fill</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.full_like">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">full_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.full_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an scalar value array with the same shape and type
as the input array</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L486</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p></li>
<li><p><strong>fill_value</strong> (<em>double</em><em>, </em><em>required</em>) – Scalar value to be filled</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.ones">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">ones</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.ones" title="Permalink to this definition">¶</a></dt>
<dd><p>Fill target with ones</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L461</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – </p></li>
<li><p><strong>dtype</strong> (<em>{'float16'</em><em>, </em><em>'float32'</em><em>, </em><em>'float64'</em><em>, </em><em>'int16'</em><em>, </em><em>'int32'</em><em>, </em><em>'int64'</em><em>, </em><em>'int8'</em><em>, </em><em>'uint16'</em><em>, </em><em>'uint32'</em><em>, </em><em>'uint64'</em><em>, </em><em>'uint8'}</em><em>,</em><em>optional</em><em>, </em><em>default='float32'</em>) – Target data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.ones_like">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">ones_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.ones_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an array of ones with the same shape and type
as the input array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.zeros">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">zeros</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.zeros" title="Permalink to this definition">¶</a></dt>
<dd><p>Fill target with zeros</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/elemwise.cc:L438</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – </p></li>
<li><p><strong>dtype</strong> (<em>{'float16'</em><em>, </em><em>'float32'</em><em>, </em><em>'float64'</em><em>, </em><em>'int16'</em><em>, </em><em>'int32'</em><em>, </em><em>'int64'</em><em>, </em><em>'int8'</em><em>, </em><em>'uint16'</em><em>, </em><em>'uint32'</em><em>, </em><em>'uint64'</em><em>, </em><em>'uint8'}</em><em>,</em><em>optional</em><em>, </em><em>default='float32'</em>) – Target data type.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.zeros_like">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">zeros_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.zeros_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an array of zeros with the same shape and type
as the input array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.slice_like">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">slice_like</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.slice_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Slice the first input respect to the second input.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L1197</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data to be sliced.</p></li>
<li><p><strong>slice_like</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Tensor with target shape</p></li>
<li><p><strong>axis</strong> (<em>tuple of &lt;int&gt;</em><em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – List of axes on which input data will be sliced according to the corresponding size of the second input. By default will slice on all axes. Negative axes are supported.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.strided_slice">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">strided_slice</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.strided_slice" title="Permalink to this definition">¶</a></dt>
<dd><p>Strided slice of an array.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">4.</span><span class="p">,</span>   <span class="mf">7.</span><span class="p">,</span>  <span class="mf">10.</span><span class="p">],</span>
     <span class="p">[</span>  <span class="mf">2.</span><span class="p">,</span>   <span class="mf">5.</span><span class="p">,</span>   <span class="mf">8.</span><span class="p">,</span>  <span class="mf">11.</span><span class="p">],</span>
     <span class="p">[</span>  <span class="mf">3.</span><span class="p">,</span>   <span class="mf">6.</span><span class="p">,</span>   <span class="mf">9.</span><span class="p">,</span>  <span class="mf">12.</span><span class="p">]]</span>

<span class="n">strided_slice</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">,</span>  <span class="mf">10.</span><span class="p">],</span>
                                                             <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span>  <span class="mf">11.</span><span class="p">]]</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
      <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]],</span>

     <span class="p">[[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
      <span class="p">[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]]]</span>

<span class="n">strided_slice</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">=</span> <span class="p">[[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
                                               <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]],</span>

                                              <span class="p">[[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
                                               <span class="p">[</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">]]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/transform.cc:L951</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Array to be sliced</p></li>
<li><p><strong>begin</strong> (<em>tuple of &lt;&gt;</em><em>, </em><em>required</em>) – Indices for begin of slice</p></li>
<li><p><strong>end</strong> (<em>tuple of &lt;&gt;</em><em>, </em><em>required</em>) – Indices for end of the slice</p></li>
<li><p><strong>stride</strong> (<em>tuple of &lt;&gt;</em><em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – Stride values of the slice</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.argmax">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates an operation that finds the indices of the maximum
values over a given axis.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/reduce.cc:L285</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – <p>The axis or axes along which to perform the reduction.</p>
<blockquote>
<div><p>The default, <cite>axis=()</cite>, will compute over all elements into a
scalar array with shape <cite>(1,)</cite>.</p>
<p>If <cite>axis</cite> is int, a reduction is performed on a particular axis.</p>
<p>If <cite>axis</cite> is a tuple of ints, a reduction is performed on all the axes
specified in the tuple.</p>
<p>If <cite>exclude</cite> is true, reduction will be performed on the axes that are
NOT in axis instead.</p>
</div></blockquote>
</p></li>
<li><p><strong>keepdims</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If this is set to <cite>True</cite>, the reduced axes are left in the result as dimension with size one.</p></li>
<li><p><strong>exclude</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to perform reduction on axis that are NOT in axis instead.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.argmin">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">argmin</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.argmin" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates an operation that finds the indices of the minimum
values over a given axis.</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/reduce.cc:L307</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – <p>The axis or axes along which to perform the reduction.</p>
<blockquote>
<div><p>The default, <cite>axis=()</cite>, will compute over all elements into a
scalar array with shape <cite>(1,)</cite>.</p>
<p>If <cite>axis</cite> is int, a reduction is performed on a particular axis.</p>
<p>If <cite>axis</cite> is a tuple of ints, a reduction is performed on all the axes
specified in the tuple.</p>
<p>If <cite>exclude</cite> is true, reduction will be performed on the axes that are
NOT in axis instead.</p>
</div></blockquote>
</p></li>
<li><p><strong>keepdims</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If this is set to <cite>True</cite>, the reduced axes are left in the result as dimension with size one.</p></li>
<li><p><strong>exclude</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to perform reduction on axis that are NOT in axis instead.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.collapse_sum">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">collapse_sum</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.collapse_sum" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduces lhs to the shape of rhs via sum</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/reduce.cc:L261</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>axis</strong> (<em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>]</em>) – <p>The axis or axes along which to perform the reduction.</p>
<blockquote>
<div><p>The default, <cite>axis=()</cite>, will compute over all elements into a
scalar array with shape <cite>(1,)</cite>.</p>
<p>If <cite>axis</cite> is int, a reduction is performed on a particular axis.</p>
<p>If <cite>axis</cite> is a tuple of ints, a reduction is performed on all the axes
specified in the tuple.</p>
<p>If <cite>exclude</cite> is true, reduction will be performed on the axes that are
NOT in axis instead.</p>
</div></blockquote>
</p></li>
<li><p><strong>keepdims</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – If this is set to <cite>True</cite>, the reduced axes are left in the result as dimension with size one.</p></li>
<li><p><strong>exclude</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to perform reduction on axis that are NOT in axis instead.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The input</p></li>
<li><p><strong>as</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – The reference</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_equal">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_equal</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_equal" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise x == y of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">5.</span><span class="p">]]</span>

<span class="n">broadcast_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L512</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_greater_equal">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_greater_equal</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_greater_equal" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise x &gt;= y of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">6.</span><span class="p">]]</span>

<span class="n">broadcast_greater_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
                                 <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L560</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_greater">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_greater</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_greater" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise x &gt; y of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">3.</span><span class="p">]]</span>

<span class="n">broadcast_greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
                           <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L466</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_left_shift">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_left_shift</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_left_shift" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise x &lt;&lt; y of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">1.</span><span class="p">]]</span>

<span class="n">broadcast_left_shift</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span>  <span class="mf">12.</span><span class="p">],</span>
                              <span class="p">[</span> <span class="mf">8.</span><span class="p">,</span>  <span class="mf">10.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L432</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_less_equal">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_less_equal</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_less_equal" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise x &lt;= y of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">5.</span><span class="p">]]</span>

<span class="n">broadcast_less_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
                              <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L585</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_less">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_less</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_less" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise x &lt; y of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">3.</span><span class="p">]]</span>

<span class="n">broadcast_less</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
                        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L489</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_max">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_max</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_max" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise max of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">3.</span><span class="p">]]</span>

<span class="n">broadcast_max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
                       <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L381</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_min">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_min</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_min" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise minimum of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">3.</span><span class="p">]]</span>

<span class="n">broadcast_min</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
                       <span class="p">[</span> <span class="mf">3.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L398</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_mod">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_mod</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_mod" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise mod of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">3.</span><span class="p">]]</span>

<span class="n">broadcast_mod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
                       <span class="p">[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L364</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_not_equal">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_not_equal</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_not_equal" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise x != y of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">]]</span>

<span class="n">broadcast_not_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">],</span>
                             <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L535</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_pow">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_pow</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_pow" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise x^y of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">2.</span><span class="p">]]</span>

<span class="n">broadcast_pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>   <span class="mf">2.</span><span class="p">,</span>   <span class="mf">3.</span> <span class="p">],</span>
                       <span class="p">[</span> <span class="mf">16.</span><span class="p">,</span>  <span class="mf">25.</span><span class="p">,</span>  <span class="mf">36.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L415</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.broadcast_right_shift">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">broadcast_right_shift</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.broadcast_right_shift" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns element-wise x &gt;&gt; y of the input arrays with broadcasting.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">,</span>  <span class="mf">12.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">8.</span><span class="p">,</span>  <span class="mf">10.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">]]</span>

<span class="n">y</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">1.</span><span class="p">]]</span>

<span class="n">broadcast_right_shift</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
                               <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/tensor/broadcast.cc:L449</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – first input</p></li>
<li><p><strong>rhs</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – second input</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.multibox_prior">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">multibox_prior</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.multibox_prior" title="Permalink to this definition">¶</a></dt>
<dd><p>“Generate prior(anchor) boxes from data, sizes and ratios.”</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/vision/ssd/mutibox_op.cc:L64</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sizes</strong> (<em>tuple of &lt;float&gt;</em><em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>1</em><em>]</em>) – List of sizes of generated MultiBoxPriores.</p></li>
<li><p><strong>ratios</strong> (<em>tuple of &lt;float&gt;</em><em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>1</em><em>]</em>) – List of aspect ratios of generated MultiBoxPriores.</p></li>
<li><p><strong>steps</strong> (<em>tuple of &lt;float&gt;</em><em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>-1</em><em>,</em><em>-1</em><em>]</em>) – Priorbox step across y and x, -1 for auto calculation.</p></li>
<li><p><strong>offsets</strong> (<em>tuple of &lt;float&gt;</em><em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>0.5</em><em>,</em><em>0.5</em><em>]</em>) – Priorbox center offsets, y and x respectively.</p></li>
<li><p><strong>clip</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Whether to clip out-of-boundary boxes.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.multibox_transform_loc">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">multibox_transform_loc</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.multibox_transform_loc" title="Permalink to this definition">¶</a></dt>
<dd><p>“Location transformation for multibox detection.”</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/vision/ssd/mutibox_op.cc:L139</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>clip</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=1</em>) – Clip out-of-boundary boxes.</p></li>
<li><p><strong>threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=0.01</em>) – Threshold to be a positive prediction.</p></li>
<li><p><strong>variances</strong> (<em>tuple of &lt;float&gt;</em><em>, </em><em>optional</em><em>, </em><em>default=</em><em>[</em><em>0.1</em><em>,</em><em>0.1</em><em>,</em><em>0.2</em><em>,</em><em>0.2</em><em>]</em>) – Variances to be decoded from box regression output.</p></li>
<li><p><strong>cls_prob</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Class probabilities.</p></li>
<li><p><strong>loc_pred</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Location regression predictions.</p></li>
<li><p><strong>anchor</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Multibox prior anchor boxes</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.nms">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">nms</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.nms" title="Permalink to this definition">¶</a></dt>
<dd><p>“Non-maximum suppression.”</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/vision/nms.cc:L61</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nms_threshold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default=0.5</em>) – Non-maximum suppression threshold.</p></li>
<li><p><strong>force_suppress</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default=0</em>) – Suppress all detections regardless of class_id.</p></li>
<li><p><strong>nms_topk</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='-1'</em>) – Keep maximum top k detections before nms, -1 for no limit.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data.</p></li>
<li><p><strong>valid_count</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Number of valid anchor boxes.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.yolo_region">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">yolo_region</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.yolo_region" title="Permalink to this definition">¶</a></dt>
<dd><p>Region layer</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/vision/yolo/region.cc:L18</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Input data</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="nnvm.symbol.yolo_reorg">
<code class="sig-prename descclassname">nnvm.symbol.</code><code class="sig-name descname">yolo_reorg</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#nnvm.symbol.yolo_reorg" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform reorg operation on input array based on the stride value.
- <strong>data</strong>: Input is 4D array of shape (batch_size, channels, in_height, in_width).
- <strong>out</strong>: Output is 4D array of shape (batch_size, channels/(stride*stride), in_height*stride, in_width*stride).</p>
<p>Defined in /media/sf_svn/tvm/nnvm/src/top/vision/yolo/reorg.cc:L41</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor"><em>Tensor</em></a>) – Data input to reorganize</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em><em>, </em><em>default='1'</em>) – Stride value</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>result</strong> – The result Tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="api/python/tensor.html#tvm.tensor.Tensor" title="tvm.tensor.Tensor">Tensor</a></p>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="genindex.html" class="btn btn-neutral float-right" title="Index" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="dev/hybrid_script.html" class="btn btn-neutral float-left" title="Hybrid Frontend Developer Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2017, tvm developers

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>